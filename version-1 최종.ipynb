{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#데이터 핸들링\nimport pandas as pd\nimport numpy as np\n\n#전처리\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n#모델\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\n\n#하이퍼 파라미터 튜닝: 보통 랜덤서치로 대략 파악한 다음 그리드 서치로 미세조정\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n\n#평가\nfrom sklearn.metrics import f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:27:50.617360Z","iopub.execute_input":"2025-06-26T11:27:50.617678Z","iopub.status.idle":"2025-06-26T11:27:50.623629Z","shell.execute_reply.started":"2025-06-26T11:27:50.617655Z","shell.execute_reply":"2025-06-26T11:27:50.622786Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Data Import\ntrain_data=pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_data=pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsample_submission=pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\ntrain_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:36:37.159373Z","iopub.execute_input":"2025-06-26T10:36:37.159680Z","iopub.status.idle":"2025-06-26T10:36:37.309615Z","shell.execute_reply.started":"2025-06-26T10:36:37.159653Z","shell.execute_reply":"2025-06-26T10:36:37.308684Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        7613 non-null   int64 \n 1   keyword   7552 non-null   object\n 2   location  5080 non-null   object\n 3   text      7613 non-null   object\n 4   target    7613 non-null   int64 \ndtypes: int64(2), object(3)\nmemory usage: 297.5+ KB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# x,y 정의\ny=train_data['target'] # a real disaster (1) or not (0)\nx=train_data.iloc[:,1:4]\nx.info()\nprint('\\n')\ny.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:36:39.346647Z","iopub.execute_input":"2025-06-26T10:36:39.347007Z","iopub.status.idle":"2025-06-26T10:36:39.367511Z","shell.execute_reply.started":"2025-06-26T10:36:39.346976Z","shell.execute_reply":"2025-06-26T10:36:39.366621Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   keyword   7552 non-null   object\n 1   location  5080 non-null   object\n 2   text      7613 non-null   object\ndtypes: object(3)\nmemory usage: 178.6+ KB\n\n\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"target\n0    4342\n1    3271\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# location 결측치 너무 많음\nprint(x.isnull().sum(),'\\n')\nfor i in range(len(x.columns)):\n    print(x.columns[i],'의 결측치 비율:', round(x.isnull().sum().iloc[i]/len(y),3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:36:42.576567Z","iopub.execute_input":"2025-06-26T10:36:42.577010Z","iopub.status.idle":"2025-06-26T10:36:42.591330Z","shell.execute_reply.started":"2025-06-26T10:36:42.576984Z","shell.execute_reply":"2025-06-26T10:36:42.590306Z"}},"outputs":[{"name":"stdout","text":"keyword       61\nlocation    2533\ntext           0\ndtype: int64 \n\nkeyword 의 결측치 비율: 0.008\nlocation 의 결측치 비율: 0.333\ntext 의 결측치 비율: 0.0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#Case1 : 결측치를 전부 결측치가 아닌 공란으로 만들기\nx1=x.fillna('unknown')\nx1.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T10:36:49.488472Z","iopub.execute_input":"2025-06-26T10:36:49.488742Z","iopub.status.idle":"2025-06-26T10:36:49.501215Z","shell.execute_reply.started":"2025-06-26T10:36:49.488723Z","shell.execute_reply":"2025-06-26T10:36:49.500231Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"keyword     0\nlocation    0\ntext        0\ndtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nfrom torch.utils.data import DataLoader\nimport torch\n\n# 1. 트위터 특화 BERT 로드\nmodel_name = \"cardiffnlp/twitter-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# 2. 문장 리스트를 CLS 임베딩으로 벡터화하는 함수\ndef get_cls_batch(texts, batch_size=16, max_len=128):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n\n    all_embeddings = []\n    dataloader = DataLoader(texts, batch_size=batch_size)\n\n    for batch in dataloader:\n        # 트윗 전처리 (선택적)\n        batch = [text.replace(\"http://\", \"\").replace(\"https://\", \"\").strip() for text in batch]\n\n        # 토크나이징\n        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len).to(device)\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS 토큰 임베딩\n\n        all_embeddings.extend(cls_embeddings.cpu().numpy())\n\n    return all_embeddings\n\nvector1 = get_cls_batch(x1['keyword'].tolist())\nvector2 = get_cls_batch(x1['location'].tolist())\nvector3 = get_cls_batch(x1['text'].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:08:39.450460Z","iopub.execute_input":"2025-06-26T11:08:39.451109Z","iopub.status.idle":"2025-06-26T11:22:02.652557Z","shell.execute_reply.started":"2025-06-26T11:08:39.451084Z","shell.execute_reply":"2025-06-26T11:22:02.651711Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"keyword=np.stack(vector1)\nlocation=np.stack(vector2)\ntext=np.stack(vector3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:26:01.252606Z","iopub.execute_input":"2025-06-26T11:26:01.253065Z","iopub.status.idle":"2025-06-26T11:26:01.324161Z","shell.execute_reply.started":"2025-06-26T11:26:01.253034Z","shell.execute_reply":"2025-06-26T11:26:01.323437Z"}},"outputs":[{"name":"stdout","text":"7613 7613 7613\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Case1-1 : 데이터를 합쳐서 사용\ndf=np.concatenate([keyword,location,text],axis=1)\nprint(df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:26:22.652831Z","iopub.execute_input":"2025-06-26T11:26:22.653233Z","iopub.status.idle":"2025-06-26T11:26:22.697712Z","shell.execute_reply.started":"2025-06-26T11:26:22.653210Z","shell.execute_reply":"2025-06-26T11:26:22.696840Z"}},"outputs":[{"name":"stdout","text":"(7613, 2304)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"p=pd.DataFrame(np.cumsum(PCA().fit(df).explained_variance_ratio_))\np[p.iloc[:,0]>0.9]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:35:48.716236Z","iopub.execute_input":"2025-06-26T11:35:48.716532Z","iopub.status.idle":"2025-06-26T11:35:54.145067Z","shell.execute_reply.started":"2025-06-26T11:35:48.716511Z","shell.execute_reply":"2025-06-26T11:35:54.143384Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"             0\n301   0.900293\n302   0.900760\n303   0.901225\n304   0.901685\n305   0.902144\n...        ...\n2299  0.999999\n2300  0.999999\n2301  0.999999\n2302  0.999999\n2303  0.999999\n\n[2003 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>301</th>\n      <td>0.900293</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>0.900760</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>0.901225</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>0.901685</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>0.902144</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2299</th>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>2300</th>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>2301</th>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>2302</th>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>2303</th>\n      <td>0.999999</td>\n    </tr>\n  </tbody>\n</table>\n<p>2003 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"pca = PCA(n_components=301)\ndf= pd.DataFrame(pca.fit_transform(df))\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:37:54.171832Z","iopub.execute_input":"2025-06-26T11:37:54.172502Z","iopub.status.idle":"2025-06-26T11:37:54.403476Z","shell.execute_reply.started":"2025-06-26T11:37:54.172478Z","shell.execute_reply":"2025-06-26T11:37:54.402594Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"           0         1         2         3         4         5         6    \\\n0     0.014092 -0.123945 -0.142184 -0.425904  0.685301  0.149631  0.353998   \n1     0.219201  0.029803 -0.187321 -0.340861 -0.064373 -0.309095 -0.012501   \n2     0.166935  0.050866 -0.148126 -0.514017 -0.060950 -0.182907  0.074843   \n3     0.092933  0.034081 -0.151584 -0.492058  0.111674 -0.116132  0.324615   \n4     0.280417  0.082046 -0.136604 -0.431632 -0.075906 -0.313430  0.293265   \n...        ...       ...       ...       ...       ...       ...       ...   \n7608 -0.135857 -0.135019 -0.248022 -0.171471 -0.340348 -0.085507  0.131151   \n7609  0.120862 -0.064160 -0.164857 -0.259708  0.100073  0.103671  0.258643   \n7610 -0.488671 -0.229063 -0.255212 -0.154704 -0.114804  0.034344  0.223804   \n7611  0.210056  0.055381 -0.104942 -0.557153  0.002414 -0.232016 -0.059444   \n7612 -0.518265 -0.041820 -0.218699 -0.482046  0.229511 -0.331292 -0.108063   \n\n           7         8         9    ...       291       292       293  \\\n0     0.445765 -0.107565 -0.185683  ...  0.027942 -0.022497  0.074955   \n1    -0.141574 -0.089826 -0.212193  ... -0.023303 -0.000163  0.026552   \n2     0.140386  0.166474 -0.384613  ... -0.006713  0.008448 -0.010423   \n3     0.349019 -0.054421 -0.337842  ... -0.003601 -0.051723 -0.000733   \n4     0.065464 -0.364440 -0.027242  ...  0.002079 -0.001229  0.055245   \n...        ...       ...       ...  ...       ...       ...       ...   \n7608 -0.005382 -0.009572 -0.004848  ...  0.000275  0.011613  0.000212   \n7609  0.200761 -0.272180 -0.245657  ... -0.021092 -0.004242 -0.038088   \n7610 -0.073223  0.009734  0.181741  ... -0.006033  0.020926  0.005501   \n7611 -0.001768 -0.271950 -0.059093  ... -0.011622 -0.051627 -0.004642   \n7612  0.002941 -0.044428 -0.299520  ... -0.018084  0.013324 -0.025188   \n\n           294       295       296       297       298       299       300  \n0    -0.012075  0.012085  0.026739  0.014626 -0.010231  0.009789  0.007717  \n1     0.003693 -0.065101 -0.002748 -0.004274  0.040424 -0.035756 -0.015860  \n2    -0.002486  0.004433 -0.004818 -0.007612 -0.031186  0.030037  0.011061  \n3    -0.029129  0.011546  0.001578  0.003999 -0.008043 -0.043656 -0.032592  \n4    -0.034899 -0.019940 -0.000396 -0.010321  0.010310  0.067268 -0.022750  \n...        ...       ...       ...       ...       ...       ...       ...  \n7608 -0.024138  0.021211  0.008918 -0.020473 -0.014121  0.008027  0.006852  \n7609 -0.014086 -0.016554  0.008352  0.009711  0.002904  0.002505  0.004681  \n7610  0.036226 -0.020360 -0.048811  0.026738 -0.075187 -0.041987 -0.049796  \n7611  0.012247 -0.016464 -0.041628  0.036180  0.036378  0.032289 -0.014012  \n7612 -0.032627  0.007222 -0.024746  0.006978  0.031743  0.010255 -0.012326  \n\n[7613 rows x 301 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n      <th>300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.014092</td>\n      <td>-0.123945</td>\n      <td>-0.142184</td>\n      <td>-0.425904</td>\n      <td>0.685301</td>\n      <td>0.149631</td>\n      <td>0.353998</td>\n      <td>0.445765</td>\n      <td>-0.107565</td>\n      <td>-0.185683</td>\n      <td>...</td>\n      <td>0.027942</td>\n      <td>-0.022497</td>\n      <td>0.074955</td>\n      <td>-0.012075</td>\n      <td>0.012085</td>\n      <td>0.026739</td>\n      <td>0.014626</td>\n      <td>-0.010231</td>\n      <td>0.009789</td>\n      <td>0.007717</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.219201</td>\n      <td>0.029803</td>\n      <td>-0.187321</td>\n      <td>-0.340861</td>\n      <td>-0.064373</td>\n      <td>-0.309095</td>\n      <td>-0.012501</td>\n      <td>-0.141574</td>\n      <td>-0.089826</td>\n      <td>-0.212193</td>\n      <td>...</td>\n      <td>-0.023303</td>\n      <td>-0.000163</td>\n      <td>0.026552</td>\n      <td>0.003693</td>\n      <td>-0.065101</td>\n      <td>-0.002748</td>\n      <td>-0.004274</td>\n      <td>0.040424</td>\n      <td>-0.035756</td>\n      <td>-0.015860</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.166935</td>\n      <td>0.050866</td>\n      <td>-0.148126</td>\n      <td>-0.514017</td>\n      <td>-0.060950</td>\n      <td>-0.182907</td>\n      <td>0.074843</td>\n      <td>0.140386</td>\n      <td>0.166474</td>\n      <td>-0.384613</td>\n      <td>...</td>\n      <td>-0.006713</td>\n      <td>0.008448</td>\n      <td>-0.010423</td>\n      <td>-0.002486</td>\n      <td>0.004433</td>\n      <td>-0.004818</td>\n      <td>-0.007612</td>\n      <td>-0.031186</td>\n      <td>0.030037</td>\n      <td>0.011061</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.092933</td>\n      <td>0.034081</td>\n      <td>-0.151584</td>\n      <td>-0.492058</td>\n      <td>0.111674</td>\n      <td>-0.116132</td>\n      <td>0.324615</td>\n      <td>0.349019</td>\n      <td>-0.054421</td>\n      <td>-0.337842</td>\n      <td>...</td>\n      <td>-0.003601</td>\n      <td>-0.051723</td>\n      <td>-0.000733</td>\n      <td>-0.029129</td>\n      <td>0.011546</td>\n      <td>0.001578</td>\n      <td>0.003999</td>\n      <td>-0.008043</td>\n      <td>-0.043656</td>\n      <td>-0.032592</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.280417</td>\n      <td>0.082046</td>\n      <td>-0.136604</td>\n      <td>-0.431632</td>\n      <td>-0.075906</td>\n      <td>-0.313430</td>\n      <td>0.293265</td>\n      <td>0.065464</td>\n      <td>-0.364440</td>\n      <td>-0.027242</td>\n      <td>...</td>\n      <td>0.002079</td>\n      <td>-0.001229</td>\n      <td>0.055245</td>\n      <td>-0.034899</td>\n      <td>-0.019940</td>\n      <td>-0.000396</td>\n      <td>-0.010321</td>\n      <td>0.010310</td>\n      <td>0.067268</td>\n      <td>-0.022750</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>-0.135857</td>\n      <td>-0.135019</td>\n      <td>-0.248022</td>\n      <td>-0.171471</td>\n      <td>-0.340348</td>\n      <td>-0.085507</td>\n      <td>0.131151</td>\n      <td>-0.005382</td>\n      <td>-0.009572</td>\n      <td>-0.004848</td>\n      <td>...</td>\n      <td>0.000275</td>\n      <td>0.011613</td>\n      <td>0.000212</td>\n      <td>-0.024138</td>\n      <td>0.021211</td>\n      <td>0.008918</td>\n      <td>-0.020473</td>\n      <td>-0.014121</td>\n      <td>0.008027</td>\n      <td>0.006852</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>0.120862</td>\n      <td>-0.064160</td>\n      <td>-0.164857</td>\n      <td>-0.259708</td>\n      <td>0.100073</td>\n      <td>0.103671</td>\n      <td>0.258643</td>\n      <td>0.200761</td>\n      <td>-0.272180</td>\n      <td>-0.245657</td>\n      <td>...</td>\n      <td>-0.021092</td>\n      <td>-0.004242</td>\n      <td>-0.038088</td>\n      <td>-0.014086</td>\n      <td>-0.016554</td>\n      <td>0.008352</td>\n      <td>0.009711</td>\n      <td>0.002904</td>\n      <td>0.002505</td>\n      <td>0.004681</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>-0.488671</td>\n      <td>-0.229063</td>\n      <td>-0.255212</td>\n      <td>-0.154704</td>\n      <td>-0.114804</td>\n      <td>0.034344</td>\n      <td>0.223804</td>\n      <td>-0.073223</td>\n      <td>0.009734</td>\n      <td>0.181741</td>\n      <td>...</td>\n      <td>-0.006033</td>\n      <td>0.020926</td>\n      <td>0.005501</td>\n      <td>0.036226</td>\n      <td>-0.020360</td>\n      <td>-0.048811</td>\n      <td>0.026738</td>\n      <td>-0.075187</td>\n      <td>-0.041987</td>\n      <td>-0.049796</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>0.210056</td>\n      <td>0.055381</td>\n      <td>-0.104942</td>\n      <td>-0.557153</td>\n      <td>0.002414</td>\n      <td>-0.232016</td>\n      <td>-0.059444</td>\n      <td>-0.001768</td>\n      <td>-0.271950</td>\n      <td>-0.059093</td>\n      <td>...</td>\n      <td>-0.011622</td>\n      <td>-0.051627</td>\n      <td>-0.004642</td>\n      <td>0.012247</td>\n      <td>-0.016464</td>\n      <td>-0.041628</td>\n      <td>0.036180</td>\n      <td>0.036378</td>\n      <td>0.032289</td>\n      <td>-0.014012</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>-0.518265</td>\n      <td>-0.041820</td>\n      <td>-0.218699</td>\n      <td>-0.482046</td>\n      <td>0.229511</td>\n      <td>-0.331292</td>\n      <td>-0.108063</td>\n      <td>0.002941</td>\n      <td>-0.044428</td>\n      <td>-0.299520</td>\n      <td>...</td>\n      <td>-0.018084</td>\n      <td>0.013324</td>\n      <td>-0.025188</td>\n      <td>-0.032627</td>\n      <td>0.007222</td>\n      <td>-0.024746</td>\n      <td>0.006978</td>\n      <td>0.031743</td>\n      <td>0.010255</td>\n      <td>-0.012326</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 301 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"#스케일링 (향후 다른 방법으로 스케일링이 필요할 수도 있습니다.)\ndf=StandardScaler().fit_transform(df)\ndf=pd.DataFrame(df)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:38:15.474599Z","iopub.execute_input":"2025-06-26T11:38:15.475235Z","iopub.status.idle":"2025-06-26T11:38:15.603795Z","shell.execute_reply.started":"2025-06-26T11:38:15.475210Z","shell.execute_reply":"2025-06-26T11:38:15.603119Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"           0         1         2         3         4         5         6    \\\n0     0.033274 -0.371930 -0.470534 -1.491461  2.582176  0.617263  1.637028   \n1     0.517580  0.089433 -0.619907 -1.193649 -0.242552 -1.275088 -0.057812   \n2     0.394170  0.152636 -0.490198 -1.800019 -0.229657 -0.754533  0.346103   \n3     0.219434  0.102269 -0.501643 -1.723121  0.420783 -0.479072  1.501151   \n4     0.662124  0.246201 -0.452068 -1.511519 -0.286008 -1.292972  1.356175   \n...        ...       ...       ...       ...       ...       ...       ...   \n7608 -0.320787 -0.405159 -0.820788 -0.600468 -1.282411 -0.352735  0.606494   \n7609  0.285382 -0.192529 -0.545567 -0.909464  0.377071  0.427666  1.196071   \n7610 -1.153857 -0.687364 -0.844582 -0.541752 -0.432576  0.141675  1.034960   \n7611  0.495987  0.166186 -0.347289 -1.951078  0.009094 -0.957117 -0.274891   \n7612 -1.223735 -0.125493 -0.723748 -1.688062  0.864783 -1.366655 -0.499726   \n\n           7         8         9    ...       291       292       293  \\\n0     2.165637 -0.538849 -1.000218  ...  0.803058 -0.646782  2.172337   \n1    -0.687800 -0.449984 -1.143016  ... -0.669735 -0.004673  0.769521   \n2     0.682030  0.833953 -2.071790  ... -0.192939  0.242870 -0.302079   \n3     1.695623 -0.272622 -1.819848  ... -0.103489 -1.487013 -0.021248   \n4     0.318043 -1.825669 -0.146742  ...  0.059745 -0.035323  1.601110   \n...        ...       ...       ...  ...       ...       ...       ...   \n7608 -0.026145 -0.047951 -0.026117  ...  0.007902  0.333858  0.006132   \n7609  0.975350 -1.363492 -1.323279  ... -0.606187 -0.121954 -1.103882   \n7610 -0.355738  0.048764  0.978982  ... -0.173383  0.601622  0.159423   \n7611 -0.008587 -1.362338 -0.318315  ... -0.334003 -1.484259 -0.134549   \n7612  0.014287 -0.222562 -1.613421  ... -0.519734  0.383055 -0.729987   \n\n           294       295       296       297       298       299       300  \n0    -0.351186  0.352222  0.781682  0.431089 -0.302140  0.291240  0.231544  \n1     0.107407 -1.897399 -0.080348 -0.125985  1.193748 -1.063761 -0.475853  \n2    -0.072312  0.129205 -0.140845 -0.224367 -0.920947  0.893605  0.331874  \n3    -0.847174  0.336499  0.046120  0.117856 -0.237529 -1.298783 -0.977871  \n4    -1.014999 -0.581159 -0.011567 -0.304213  0.304461  2.001264 -0.682564  \n...        ...       ...       ...       ...       ...       ...       ...  \n7608 -0.702035  0.618201  0.260711 -0.603410 -0.417010  0.238792  0.205596  \n7609 -0.409670 -0.482474  0.244142  0.286229  0.085761  0.074517  0.140440  \n7610  1.053579 -0.593410 -1.426920  0.788071 -2.220323 -1.249145 -1.494037  \n7611  0.356191 -0.479856 -1.216937  1.066368  1.074252  0.960616 -0.420391  \n7612 -0.948912  0.210502 -0.723420  0.205681  0.937378  0.305096 -0.369818  \n\n[7613 rows x 301 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n      <th>300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.033274</td>\n      <td>-0.371930</td>\n      <td>-0.470534</td>\n      <td>-1.491461</td>\n      <td>2.582176</td>\n      <td>0.617263</td>\n      <td>1.637028</td>\n      <td>2.165637</td>\n      <td>-0.538849</td>\n      <td>-1.000218</td>\n      <td>...</td>\n      <td>0.803058</td>\n      <td>-0.646782</td>\n      <td>2.172337</td>\n      <td>-0.351186</td>\n      <td>0.352222</td>\n      <td>0.781682</td>\n      <td>0.431089</td>\n      <td>-0.302140</td>\n      <td>0.291240</td>\n      <td>0.231544</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.517580</td>\n      <td>0.089433</td>\n      <td>-0.619907</td>\n      <td>-1.193649</td>\n      <td>-0.242552</td>\n      <td>-1.275088</td>\n      <td>-0.057812</td>\n      <td>-0.687800</td>\n      <td>-0.449984</td>\n      <td>-1.143016</td>\n      <td>...</td>\n      <td>-0.669735</td>\n      <td>-0.004673</td>\n      <td>0.769521</td>\n      <td>0.107407</td>\n      <td>-1.897399</td>\n      <td>-0.080348</td>\n      <td>-0.125985</td>\n      <td>1.193748</td>\n      <td>-1.063761</td>\n      <td>-0.475853</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.394170</td>\n      <td>0.152636</td>\n      <td>-0.490198</td>\n      <td>-1.800019</td>\n      <td>-0.229657</td>\n      <td>-0.754533</td>\n      <td>0.346103</td>\n      <td>0.682030</td>\n      <td>0.833953</td>\n      <td>-2.071790</td>\n      <td>...</td>\n      <td>-0.192939</td>\n      <td>0.242870</td>\n      <td>-0.302079</td>\n      <td>-0.072312</td>\n      <td>0.129205</td>\n      <td>-0.140845</td>\n      <td>-0.224367</td>\n      <td>-0.920947</td>\n      <td>0.893605</td>\n      <td>0.331874</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.219434</td>\n      <td>0.102269</td>\n      <td>-0.501643</td>\n      <td>-1.723121</td>\n      <td>0.420783</td>\n      <td>-0.479072</td>\n      <td>1.501151</td>\n      <td>1.695623</td>\n      <td>-0.272622</td>\n      <td>-1.819848</td>\n      <td>...</td>\n      <td>-0.103489</td>\n      <td>-1.487013</td>\n      <td>-0.021248</td>\n      <td>-0.847174</td>\n      <td>0.336499</td>\n      <td>0.046120</td>\n      <td>0.117856</td>\n      <td>-0.237529</td>\n      <td>-1.298783</td>\n      <td>-0.977871</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.662124</td>\n      <td>0.246201</td>\n      <td>-0.452068</td>\n      <td>-1.511519</td>\n      <td>-0.286008</td>\n      <td>-1.292972</td>\n      <td>1.356175</td>\n      <td>0.318043</td>\n      <td>-1.825669</td>\n      <td>-0.146742</td>\n      <td>...</td>\n      <td>0.059745</td>\n      <td>-0.035323</td>\n      <td>1.601110</td>\n      <td>-1.014999</td>\n      <td>-0.581159</td>\n      <td>-0.011567</td>\n      <td>-0.304213</td>\n      <td>0.304461</td>\n      <td>2.001264</td>\n      <td>-0.682564</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>-0.320787</td>\n      <td>-0.405159</td>\n      <td>-0.820788</td>\n      <td>-0.600468</td>\n      <td>-1.282411</td>\n      <td>-0.352735</td>\n      <td>0.606494</td>\n      <td>-0.026145</td>\n      <td>-0.047951</td>\n      <td>-0.026117</td>\n      <td>...</td>\n      <td>0.007902</td>\n      <td>0.333858</td>\n      <td>0.006132</td>\n      <td>-0.702035</td>\n      <td>0.618201</td>\n      <td>0.260711</td>\n      <td>-0.603410</td>\n      <td>-0.417010</td>\n      <td>0.238792</td>\n      <td>0.205596</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>0.285382</td>\n      <td>-0.192529</td>\n      <td>-0.545567</td>\n      <td>-0.909464</td>\n      <td>0.377071</td>\n      <td>0.427666</td>\n      <td>1.196071</td>\n      <td>0.975350</td>\n      <td>-1.363492</td>\n      <td>-1.323279</td>\n      <td>...</td>\n      <td>-0.606187</td>\n      <td>-0.121954</td>\n      <td>-1.103882</td>\n      <td>-0.409670</td>\n      <td>-0.482474</td>\n      <td>0.244142</td>\n      <td>0.286229</td>\n      <td>0.085761</td>\n      <td>0.074517</td>\n      <td>0.140440</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>-1.153857</td>\n      <td>-0.687364</td>\n      <td>-0.844582</td>\n      <td>-0.541752</td>\n      <td>-0.432576</td>\n      <td>0.141675</td>\n      <td>1.034960</td>\n      <td>-0.355738</td>\n      <td>0.048764</td>\n      <td>0.978982</td>\n      <td>...</td>\n      <td>-0.173383</td>\n      <td>0.601622</td>\n      <td>0.159423</td>\n      <td>1.053579</td>\n      <td>-0.593410</td>\n      <td>-1.426920</td>\n      <td>0.788071</td>\n      <td>-2.220323</td>\n      <td>-1.249145</td>\n      <td>-1.494037</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>0.495987</td>\n      <td>0.166186</td>\n      <td>-0.347289</td>\n      <td>-1.951078</td>\n      <td>0.009094</td>\n      <td>-0.957117</td>\n      <td>-0.274891</td>\n      <td>-0.008587</td>\n      <td>-1.362338</td>\n      <td>-0.318315</td>\n      <td>...</td>\n      <td>-0.334003</td>\n      <td>-1.484259</td>\n      <td>-0.134549</td>\n      <td>0.356191</td>\n      <td>-0.479856</td>\n      <td>-1.216937</td>\n      <td>1.066368</td>\n      <td>1.074252</td>\n      <td>0.960616</td>\n      <td>-0.420391</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>-1.223735</td>\n      <td>-0.125493</td>\n      <td>-0.723748</td>\n      <td>-1.688062</td>\n      <td>0.864783</td>\n      <td>-1.366655</td>\n      <td>-0.499726</td>\n      <td>0.014287</td>\n      <td>-0.222562</td>\n      <td>-1.613421</td>\n      <td>...</td>\n      <td>-0.519734</td>\n      <td>0.383055</td>\n      <td>-0.729987</td>\n      <td>-0.948912</td>\n      <td>0.210502</td>\n      <td>-0.723420</td>\n      <td>0.205681</td>\n      <td>0.937378</td>\n      <td>0.305096</td>\n      <td>-0.369818</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 301 columns</p>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(df,y,train_size=0.7,random_state=123)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.85, random_state=123)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:38:27.077478Z","iopub.execute_input":"2025-06-26T11:38:27.078261Z","iopub.status.idle":"2025-06-26T11:38:27.098872Z","shell.execute_reply.started":"2025-06-26T11:38:27.078235Z","shell.execute_reply":"2025-06-26T11:38:27.097846Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"* 과적합 확인: 학습데이터 정확도- 검증 데이터 정확도\n* 0 ~ 0.05 (0~5%): 과적합 의심 적음, 안정적\n","metadata":{}},{"cell_type":"code","source":"# Case1-1-1: 랜덤포레스트\n\nRFmodel=RandomForestClassifier(random_state=123).fit(x_train,y_train)\ny_pred1=RFmodel.predict(x_test)\n\ntrain_score=RFmodel.score(x_train,y_train)\nvalidation_score=RFmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred1),3)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:38:50.865972Z","iopub.execute_input":"2025-06-26T11:38:50.866309Z","iopub.status.idle":"2025-06-26T11:38:59.815092Z","shell.execute_reply.started":"2025-06-26T11:38:50.866285Z","shell.execute_reply":"2025-06-26T11:38:59.814271Z"}},"outputs":[{"name":"stdout","text":"0.226 => 과적합\nf1 score = 0.714\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"#하이퍼 파라미터 튜닝\n\np = {\n    'n_estimators': [100, 300, 500],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 0.5],\n    'bootstrap': [True, False]\n}\ng1=RandomizedSearchCV(RFmodel,param_distributions=p,cv=5,n_iter=50,random_state).fit(x_train,y_train)\ng2=GridSearchCV(RFmodel,param_grid=p,cv=5).fit(x_train,y_train)\ng1.best_params_\ng2.best_params_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T01:22:35.181715Z","iopub.execute_input":"2025-06-26T01:22:35.181962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"RFmodel=RandomForestClassifier(n_estimators=200,max_depth=10,bootstrap=True,max_depth=,min_samples_split,min_samples_leaf=,max_features=).fit(x_train,y_train)\ny_pred1=RFmodel.predict(x_test)\n\n\ntrain_score=RFmodel.score(x_train,y_train)\nvalidation_score=RFmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred1),3)) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Case1-1-2: NaiveBayes\n\nNBmodel=GaussianNB().fit(x_train,y_train)\ny_pred2=NBmodel.predict(x_test)\n\n\ntrain_score=NBmodel.score(x_train,y_train)\nvalidation_score=NBmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred2),3)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:39:29.905107Z","iopub.execute_input":"2025-06-26T11:39:29.905405Z","iopub.status.idle":"2025-06-26T11:39:30.033409Z","shell.execute_reply.started":"2025-06-26T11:39:29.905385Z","shell.execute_reply":"2025-06-26T11:39:30.032559Z"}},"outputs":[{"name":"stdout","text":"0.034 => 과적합 아님\nf1 score = 0.614\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Case 1-1-3: 로지스틱\n\nLRmodel=LogisticRegression(max_iter=1000).fit(x_train,y_train)\ny_pred3=LRmodel.predict(x_test)\n\ntrain_score=LRmodel.score(x_train,y_train)\nvalidation_score=LRmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred3),3)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:39:44.211854Z","iopub.execute_input":"2025-06-26T11:39:44.212244Z","iopub.status.idle":"2025-06-26T11:39:44.385693Z","shell.execute_reply.started":"2025-06-26T11:39:44.212220Z","shell.execute_reply":"2025-06-26T11:39:44.384967Z"}},"outputs":[{"name":"stdout","text":"0.041 => 과적합 아님\nf1 score = 0.778\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"p={'C':[0.001,0.01,0.1,1],'solver':['lbfgs'],'max_iter':[500,1000,1500],'class_weight': [None, 'balanced']}\n\ng1=RandomizedSearchCV(LRmodel,param_distributions=p,cv=5,n_iter=50,random_state).fit(x_train,y_train)\ng2=GridSearchCV(LRmodel,param_grid=p,cv=5).fit(x_train,y_train)\nprint(g1.best_params_)\nprint(g2.best_params_)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LRmodel=LogisticRegression(max_iter= 500,C= 0.001,class_weight= None).fit(x_train,y_train)\ny_pred3=LRmodel.predict(x_test)\n\ntrain_score=LRmodel.score(x_train,y_train)\nvalidation_score=LRmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred3),3)) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Case 1-1-4: SVM\n\nSVCmodel=SVC().fit(x_train,y_train)\ny_pred4=SVCmodel.predict(x_test)\n\n\ntrain_score=SVCmodel.score(x_train,y_train)\nvalidation_score=SVCmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred4),3)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:39:59.128760Z","iopub.execute_input":"2025-06-26T11:39:59.129419Z","iopub.status.idle":"2025-06-26T11:40:12.125290Z","shell.execute_reply.started":"2025-06-26T11:39:59.129392Z","shell.execute_reply":"2025-06-26T11:40:12.124374Z"}},"outputs":[{"name":"stdout","text":"0.127 => 과적합\nf1 score = 0.779\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"#하이퍼 파라미터 튜닝\nfrom sklearn.model_selection import RandomizedSearchCV\np = {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}\n\ng1=RandomizedSearchCV(SVCmodel,param_distributions=p,cv=5,n_iter=50,random_state).fit(x_train,y_train)\ng2=GridSearchCV(SVCmodel,param_grid=p,cv=5).fit(x_train,y_train)\nprint(g1.best_params_)\nprint(g2.best_params_)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SVCmodel=SVC(C=,gamma=,kernel='').fit(x_train,y_train)\ny_pred4=SVCmodel.predict(x_test)\n\n\ntrain_score=SVCmodel.score(x_train,y_train)\nvalidation_score=SVCmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred4),3)) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Case 1-1-5: 의사결정트리\n\nDTCmodel=DecisionTreeClassifier(random_state=123).fit(x_train,y_train)\ny_pred5=DTCmodel.predict(x_test)\n\ntrain_score=DTCmodel.score(x_train,y_train)\nvalidation_score=DTCmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred5),3)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:40:30.796356Z","iopub.execute_input":"2025-06-26T11:40:30.796681Z","iopub.status.idle":"2025-06-26T11:40:33.084328Z","shell.execute_reply.started":"2025-06-26T11:40:30.796656Z","shell.execute_reply":"2025-06-26T11:40:33.083441Z"}},"outputs":[{"name":"stdout","text":"0.31 => 과적합\nf1 score = 0.644\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"p={'criterion':['gini','entrophy'],'max_depth':range(5,21).tolist,'class_weight':[None,'balanced']}\n\ng1=RandomizedSearchCV(DTCmodel,param_distributions=p,cv=5,n_iter=50,random_state).fit(x_train,y_train)\ng2=GridSearchCV(DTCmodel,param_grid=p,cv=5).fit(x_train,y_train)\nprint(g1.best_params_)\nprint(g2.best_params_)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DTCmodel=DecisionTreeClassifier(criterion='',max_depth=,class_weight=).fit(x_train,y_train)\ny_pred5=DTCmodel.predict(x_test)\n\n\ntrain_score=DTCmodel.score(x_train,y_train)\nvalidation_score=DTCmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred5),3)) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Case 1-1-6: XGBooster\nXGBmodel= XGBClassifier().fit(x_train,y_train)\ny_pred6=XGBmodel.predict(x_test)\n\ntrain_score=XGBmodel.score(x_train,y_train)\nvalidation_score=XGBmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred6),3)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T11:40:42.652654Z","iopub.execute_input":"2025-06-26T11:40:42.653427Z","iopub.status.idle":"2025-06-26T11:40:48.012588Z","shell.execute_reply.started":"2025-06-26T11:40:42.653395Z","shell.execute_reply":"2025-06-26T11:40:48.011801Z"}},"outputs":[{"name":"stdout","text":"0.215 => 과적합\nf1 score = 0.757\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"p = {'max_depth': [3, 5, 7],             \n    'learning_rate': [0.01, 0.1, 0.2],  \n    'n_estimators': [100, 200, 300],   \n    'subsample': [0.6, 0.8, 1.0],       \n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'gamma': [0, 0.1, 0.3],             \n    'min_child_weight': [1, 3, 5],      \n    'scale_pos_weight': [1, sum(negative) / sum(positive)]}\n\ng1=RandomizedSearchCV(XGBmodel,param_distributions=p,cv=5,n_iter=50,random_state).fit(x_train,y_train)\ng2=GridSearchCV(XGBmodel,param_grid=p,cv=5).fit(x_train,y_train)\nprint(g1.best_params_)\nprint(g2.best_params_)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-06-25T19:17:45.321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"XGBmodel= XGBClasifier(max_depth=,learning_rate=,n_estimators=,subsamle=,colsample_bytree=,gamma=,min_child_weight=,scale_pos_weight=).fit(x_train,y_train)\ny_pred6=XGBmodel.predict(x_test)\n\ntrain_score=XGBmodel.score(x_train,y_train)\nvalidation_score=XGBmodel.score(x_val,y_val)\n\ndiffer=round((train_score-validation_score),3)\n\n\nif not 0<=differ<=0.05:\n    print(differ,'=> 과적합')\nelse:\n    print(differ,'=> 과적합 아님')\n\n\nprint('f1 score =',round(f1_score(y_test,y_pred6),3)) ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}